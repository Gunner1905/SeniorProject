import java.io.IOException;
import java.text.SimpleDateFormat;
import java.util.ArrayList;
import java.util.Date;
import java.util.HashMap;
import java.util.List;
import java.util.Map.Entry;
import java.util.logging.Logger;
import java.lang.Object;
import java.sql.Connection;
import java.sql.DriverManager;
import java.sql.ResultSet;
import java.sql.SQLException;
import java.sql.Statement;

import twitter4j.conf.*;
import zemberek.morphology.apps.TurkishMorphParser;
import zemberek.morphology.parser.MorphParse;
import twitter4j.HashtagEntity;
import twitter4j.Query;
import twitter4j.QueryResult;
import twitter4j.Status;
import twitter4j.Twitter;
import twitter4j.TwitterException;
import twitter4j.TwitterFactory;
import twitter4j.UserMentionEntity;
import twitter4j.auth.AccessToken;
import twitter4j.auth.RequestToken;

import weka.core.Instance;
import weka.core.Instances;
import weka.experiment.InstanceQuery;
import weka.classifiers.Classifier;
import weka.classifiers.Evaluation;
import weka.classifiers.evaluation.NominalPrediction;
import weka.classifiers.lazy.IBk;
import weka.classifiers.rules.DecisionTable;
import weka.classifiers.rules.PART;
import weka.classifiers.trees.DecisionStump;
import weka.classifiers.trees.J48;
import weka.clusterers.SimpleKMeans;
import weka.core.FastVector;


import java.io.BufferedReader;
import java.io.BufferedWriter;
import java.io.FileNotFoundException;
import java.io.FileReader;
import java.io.FileWriter;





public class TwitterApplication {

	private final Logger logger = Logger.getLogger(TwitterApplication.class.getName());
	private String CONSUMER_KEY="OR611vX1xkmnuXLwD0tRwpy7D";
	private String CONSUMER_SECRET="F4REstjhTx75xzwO0dFamRLayEj4gjPYYeKzWBwfsnEMZc4Uf7";
	Database d = new Database();
	private String MYSQL_DRIVER = "com.mysql.jdbc.Driver";
	String databaseURL = "jdbc:mysql://localhost:3306/Twitter";
	
	Connection con = null;
	Statement st = null;
	BufferedWriter bufferedWriter=null;
	   
	
	   
	
	public static void main(String[] args) throws Exception {
		// TODO Auto-generated method stub
		
		//new TwitterApplication().retrieve();
		
	/*	TurkishMorphParser parser;
		try {
			parser = TurkishMorphParser.createWithDefaults();
		} catch (IOException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}
		ArrayList<String> parsedList = new ArrayList<String>(); */
		//Database d = new Database();
		
	    
		//d.addTweets();	
	//	d.showTweets();
		
		//d.dropTweetTable();
		
		
		BufferedReader datafile = readDataFile("dosya.txt");
		 
		Instances data = new Instances(datafile);
		data.setClassIndex(data.numAttributes() - 1);
 
		// Do 10-split cross validation
		   //Instances[][] split = crossValidationSplit(data, 10);
 
		// Separate split into training and testing arrays
		  //Instances[] trainingSplits = split[0];
	     //Instances[] testingSplits = split[1];
		
		SimpleKMeans kMeans = new SimpleKMeans();
		kMeans.setNumClusters(3);
		kMeans.buildClusterer(data);
		
		Instances centroids = kMeans.getClusterCentroids();
		
		for (int i = 0; i < centroids.numInstances(); i++) { 
		      System.out.println( "Centroid " + i+1 + ": " + centroids.instance(i)); 
		}
		
		for (int i = 0; i < data.numInstances(); i++) { 
		      System.out.println( data.instance(i) + " is in cluster " + kMeans.clusterInstance(data.instance(i)) + 1); 

		} 

		
		Instance first = data.instance(0);
		Instance second = data.instance(1);
		data.delete(0);
		data.delete(1);
		
		Classifier ibk = new IBk();
		ibk.buildClassifier(data);
		
		double class1 = ibk.classifyInstance(first);
		double class2 = ibk.classifyInstance(second);
		
		System.out.println("first: " + class1 + "\nsecond: " + class2);
		
		// Use a set of classifiers
			/*	Classifier[] models = { 
						new J48(), // a decision tree
						new PART(), 
						new DecisionTable(),//decision table majority classifier
						new DecisionStump() //one-level decision tree
				};
				
				// Run for each model
				for (int j = 0; j < models.length; j++) {
		 
					// Collect every group of predictions for current model in a FastVector
					FastVector predictions = new FastVector();
		 
					// For each training-testing split pair, train and test the classifier
					for (int i = 0; i < trainingSplits.length; i++) {
						Evaluation validation = classify(models[j], trainingSplits[i], testingSplits[i]);
		 
						//predictions.appendElements(validation.predictions());
		 
						// Uncomment to see the summary for each training-testing pair.
						System.out.println(models[j].toString());
					}
		 
					// Calculate overall accuracy of current classifier on all splits
					double accuracy = calculateAccuracy(predictions);
		 
					// Print current classifier's name and accuracy in a complicated,
					// but nice-looking way.
					System.out.println("Accuracy of " + models[j].getClass().getSimpleName() + ": "
							+ String.format("%.2f%%", accuracy)
							+ "\n---------------------------------");
				} */
		
		
	}
	
	public void retrieve() throws IOException{
		logger.info("Retrieving tweets...");
		ConfigurationBuilder builder = new ConfigurationBuilder();
		builder.setOAuthConsumerKey(CONSUMER_KEY);
		builder.setOAuthConsumerSecret(CONSUMER_SECRET);
		Configuration configuration = builder.build();
		TwitterFactory factory = new TwitterFactory(configuration);
		Twitter twitter = factory.getInstance();
		
		ArrayList<String> tweetList = new ArrayList<String>(); //ilk query icin
		ArrayList<String> tweetList2 = new ArrayList<String>(); //ikinci query icin
		ArrayList<String> hashtagList = new ArrayList<String>();
		ArrayList<String> mentionList = new ArrayList<String>();
		
		int tweetPoint = 0;
	//	Twitter twitter = new TwitterFactory().getInstance();
		
		//String user = "Ahmet_Karabas";
		
		
		Query query = new Query("diriliş ertuğrul" + " -filter:retweets -filter:links -filter:replies -filter:images -filter:mentions"); //
		//hashtagler icin de arastir
		
		Date date=new Date();
		String modifiedDate= new SimpleDateFormat("2015-12-15").format(date);
		String modifiedDate2= new SimpleDateFormat("2015-12-18" ).format(date);
        query.setSince(modifiedDate);
        query.setUntil(modifiedDate2);
        

        query.lang("tr");
		query.setCount(100);
		
		//query.setSince("2011-01-01");
		System.out.println("key:" + twitter.getConfiguration().getOAuthConsumerKey());
		System.out.println("secret: " + twitter.getConfiguration().getOAuthConsumerSecret());
		AccessToken accessToken = new AccessToken("344727895-ZgyHyzGDeZsSuZduKB8wythNfu4yJm8jYHTBdw3f", "m8Jbf2e4HwFOjHvNTiT6rOLqJlH5LQBW9V0nOHaIY7Dea");
	  //  twitter.setOAuthConsumer("OR611vX1xkmnuXLwD0tRwpy7D", "F4REstjhTx75xzwO0dFamRLayEj4gjPYYeKzWBwfsnEMZc4Uf7");
	    twitter.setOAuthAccessToken(accessToken);
		
		try {
					
		QueryResult result = twitter.search(query);
		
		System.out.println("Count : " + result.getTweets().size()) ;		
		
		//d.dropAllWords();
		
		// adding words to database
		//d.addWords();
				
		for (Status tweet : result.getTweets()) {	//her tweet icin		
			
		tweetPoint=0; // tweet puanini sifirliyoruz	
			
		for(HashtagEntity hashtag : tweet.getHashtagEntities()){
			//System.out.println(hashtag);
			hashtagList.add(hashtag.getText().toString());
		}
		
		for(UserMentionEntity mention : tweet.getUserMentionEntities()){
			mentionList.add(mention.getScreenName().toString());
		}
		
	   // System.out.println("@"+tweet.getUser().getScreenName() + " text : " + tweet.getText() + " count : " + tweet.getRetweetCount());
		
		
		
		tweetList.add(tweet.getText());	
	
	//	Database d = new Database();
		TurkishMorphParser parser = TurkishMorphParser.createWithDefaults();
		 Class.forName(MYSQL_DRIVER);
	      System.out.println("Class Loaded....");
	      con = DriverManager.getConnection(databaseURL,"","");
	      System.out.println("Inserting data....");
	      st = con.createStatement();
	      
		
		String tweetLabel;
		
		String msg = tweet.getText();
		
		String[] input = msg.split(" ");
		for(int j = 0;  j < input.length; j++)
		{
		System.out.println(input[j]);
		input[j].contains("");
		new ParseWords(parser).parse(input[j]);
		ResultSet rs = st.executeQuery("select * from symbols");
		while(rs.next()){
		System.out.println("Db den " +rs.getString("symbol_name"));
		if(input[j].contains(rs.getString("symbol_name"))){
			tweetPoint=tweetPoint+rs.getInt(3);
		}
		}
		System.out.println("puanımız "+tweetPoint);
		
		}
		
		
		
		//List<MorphParse> parses = parser.parse(tweet.getText());
		//System.out.println("Kelime kökü"+parses);
		
		/*for(MorphParse parse : parses)
		{
			System.out.println("Kelime kökü" +parse.formatLong());
		} */
		
		
		//System.out.println(parsedWord);
		//Calculating tweet point
				

		if(tweetPoint>0)
		{
			tweetLabel="positive";
		}
		else if(tweetPoint<0)
		{
			tweetLabel="negative";
		}
		else{
			tweetLabel="neutral";
		}
		
		java.sql.Date tweetDate = convertJavaDateToSqlDate(tweet.getCreatedAt());
		d.addTweets(tweetDate,tweet.getRetweetCount(),tweetPoint,tweetLabel);
		
		
		}
		
		//Query query = new Query(hashtagList.t + " -filter:retweets -filter:links -filter:replies -filter:images");
		//QueryResult result2 = twitter.search(query);
		
		//for()
		
		} catch (TwitterException e) {
		
		e.printStackTrace();
		System.out.println("Failed to search tweets" + e.getMessage());
		}
		catch(ClassNotFoundException ex) {
		       System.out.println("ClassNotFoundException:\n"+ex.toString());
		       ex.printStackTrace();

		    } catch(SQLException ex) {
		        System.out.println("SQLException:\n"+ex.toString());
		        ex.printStackTrace();
		    }
		
		
    /*    System.out.println("Tweets:");
		for(String t :tweetList){
			System.out.println(t); 
			
			//parsedList.add(new ParseWords(parser).parse(t));
		} */
		
		HashMap<String,Integer> hashmap = new HashMap<String,Integer>();
		System.out.println("Hashtags:");
		for(String h:hashtagList){ //hashtaglarin bulunma sayisi bulunuyor
			System.out.println(h);
			if(hashmap.containsKey(h))
			{
				hashmap.put(h, hashmap.get(h)+1);
			}
			else{
			hashmap.put(h, 1);
			}
		} 
		int max=0;
		String maxHashtag="";
		for(Entry<String,Integer> entry : hashmap.entrySet())
		{	
			if(entry.getValue()>max){
				max=entry.getValue();		
				maxHashtag=entry.getKey();
			}
		}
		
		System.out.println("En cok bulunan hashtag: " + maxHashtag);
		 
		//En cok bulunan hashtag ile yeniden aratiliyor
		Query queryNew = new Query(maxHashtag + " -filter:retweets -filter:links -filter:replies -filter:images -filter:mentions");
		
		String modifiedDate3= new SimpleDateFormat("2015-12-15").format(date);
		String modifiedDate4= new SimpleDateFormat("2015-12-18" ).format(date);
        queryNew.setSince(modifiedDate3);
        queryNew.setUntil(modifiedDate4);
        

        queryNew.lang("tr");
		queryNew.setCount(100);
		
		try {
			
			QueryResult result2 = twitter.search(queryNew);
			
			System.out.println("Count : " + result2.getTweets().size()) ;		
			
			//d.dropAllWords();
			
			
					
			for (Status tweet : result2.getTweets()) {	//her tweet icin
							
				tweetList2.add(tweet.getText());			
					
				
				tweetPoint = 0;
				String tweetLabel;
				
				String msg2 = tweet.getText();
				
				String[] input = msg2.split(" ");
				for(int j = 0;  j < input.length; j++)
				{
				System.out.println(input[j]);
				input[j].contains("");
				}
				
				//Calculating tweet point
				if(tweetPoint>0)
				{
					tweetLabel="positive";
				}
				else if(tweetPoint<0)
				{
					tweetLabel="negative";
				}
				else{
					tweetLabel="neutral";
				}
				
				java.sql.Date tweetDate = convertJavaDateToSqlDate(tweet.getCreatedAt());
				
				d.addTweets(tweetDate,tweet.getRetweetCount(),tweetPoint,tweetLabel);	
				
			}
		
			
			
		}
		 catch (TwitterException e) {
				
				e.printStackTrace();
				System.out.println("Failed to search tweets" + e.getMessage());
				
				}	
		
	    
		d.showTweets();
		logger.info("done! ");
			
	}
	public java.sql.Date convertJavaDateToSqlDate(java.util.Date date) {
	    return new java.sql.Date(date.getTime());
	}
	
	public void searchTweets(){
		
		
	}
	 
	 void usingWeka() throws Exception
	 {
		 InstanceQuery iq = new InstanceQuery();
		 iq.setUsername("nobody");
		 iq.setQuery("select * from tweets");
		 
		 Instances data = iq.retrieveInstances();
		 
		 J48 j48 = new J48();	 
	 }
	 
	 public static BufferedReader readDataFile(String filename) {
			BufferedReader inputReader = null;
	 
			try {
				inputReader = new BufferedReader(new FileReader(filename));
			} catch (FileNotFoundException ex) {
				System.err.println("File not found: " + filename);
			}
	 
			return inputReader;
		}
	 public static Evaluation classify(Classifier model,
				Instances trainingSet, Instances testingSet) throws Exception {
			Evaluation evaluation = new Evaluation(trainingSet);
	 
			model.buildClassifier(trainingSet);
			evaluation.evaluateModel(model, testingSet);
	 
			return evaluation;
		}
	 
	 public static double calculateAccuracy(FastVector predictions) {
			double correct = 0;
	 
			for (int i = 0; i < predictions.size(); i++) {
				NominalPrediction np = (NominalPrediction) predictions.elementAt(i);
				if (np.predicted() == np.actual()) {
					correct++;
				}
			}
	 
			return 100 * correct / predictions.size();
		}
	 public static Instances[][] crossValidationSplit(Instances data, int numberOfFolds) {
			Instances[][] split = new Instances[2][numberOfFolds];
	 
			for (int i = 0; i < numberOfFolds; i++) {
				split[0][i] = data.trainCV(numberOfFolds, i);
				split[1][i] = data.testCV(numberOfFolds, i);
			}
	 
			return split;
		}
 	 
	
}


